{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. An√°lisis Exploratorio de Datos (EDA)\n",
    "Antes de entrenar modelos, debemos analizar qu√© variables pueden ser m√°s relevantes para la predicci√≥n.\n",
    "\n",
    "‚úÖ Tareas a realizar:\n",
    "Cargar y visualizar el dataset\n",
    "\n",
    "Verificar estructura (df.info(), df.describe())\n",
    "Identificar valores nulos o at√≠picos (df.isnull().sum())\n",
    "Distribuci√≥n del target (target)\n",
    "\n",
    "Verificar balance de clases (df['target'].value_counts())\n",
    "Si est√° desbalanceado, considerar t√©cnicas de balanceo (SMOTE, undersampling, etc.)\n",
    "An√°lisis de correlaci√≥n\n",
    "\n",
    "Matriz de correlaci√≥n entre variables (df.corr())\n",
    "Identificar qu√© variables tienen alta correlaci√≥n con el target\n",
    "An√°lisis de importancia de variables\n",
    "\n",
    "Usar modelos basados en √°rboles (RandomForest, XGBoost) para medir importancia de features\n",
    "‚öô 2. Feature Engineering\n",
    "Una vez entendido el dataset, podemos crear nuevas caracter√≠sticas y descartar las menos relevantes.\n",
    "\n",
    "‚úÖ Posibles mejoras en las features:\n",
    "‚úî Feature Scaling: Normalizaci√≥n o estandarizaci√≥n de indicadores t√©cnicos y econ√≥micos.\n",
    "‚úî Lags & Moving Averages: Agregar ventanas m√≥viles de indicadores (RSI, MACD, SMA, volatilidad).\n",
    "‚úî Diferencias y ratios: Cambios porcentuales en close, volume, RSI, etc.\n",
    "‚úî Interacci√≥n de variables: Cruce entre sentiment_score y price_trend.\n",
    "‚úî Encoding de fecha: Convertir day_of_week, is_market en variables categ√≥ricas.\n",
    "\n",
    "ü§ñ 3. Selecci√≥n de Modelos de Machine Learning\n",
    "Queremos predecir si el precio sube o baja en la siguiente hora. Podemos probar varios modelos y comparar su desempe√±o.\n",
    "\n",
    "‚úÖ Modelos candidatos:\n",
    "Modelo\tCaracter√≠sticas\n",
    "Logistic Regression\tR√°pido y f√°cil de interpretar, pero limitado\n",
    "Random Forest\tBuen desempe√±o con datos tabulares, captura relaciones no lineales\n",
    "XGBoost\tM√°s preciso que RF, pero necesita ajuste de hiperpar√°metros\n",
    "LSTM (Red Neuronal)\tBueno para secuencias, pero requiere m√°s datos y ajuste\n",
    "SVM\tFunciona bien en espacios de alta dimensi√≥n, pero es lento\n",
    "M√©tricas clave para evaluar los modelos\n",
    "‚úî Accuracy: Qu√© tan bien clasifica en general.\n",
    "‚úî Precision-Recall: Evaluar bien los falsos positivos y negativos.\n",
    "‚úî Matriz de confusi√≥n: Para ver d√≥nde se equivoca el modelo.\n",
    "‚úî AUC-ROC: Medir la capacidad del modelo de distinguir entre subida y bajada.\n",
    "\n",
    "üöÄ 4. Entrenamiento y Evaluaci√≥n del Modelo\n",
    "Ahora podemos probar los modelos y ver cu√°l funciona mejor.\n",
    "\n",
    "‚úÖ Pasos:\n",
    "Dividir los datos en entrenamiento (70%), validaci√≥n (15%) y prueba (15%).\n",
    "Entrenar modelos con GridSearchCV para optimizar hiperpar√°metros.\n",
    "Evaluar desempe√±o y comparar modelos.\n",
    "Guardar el mejor modelo y realizar predicciones en tiempo real.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
