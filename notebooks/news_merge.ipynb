{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ticker = 'NVDA'\n",
    "original_df = pd.read_csv('../data/df_news.csv')\n",
    "filtered_df = original_df[original_df['ticker'] == target_ticker].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['overall_sentiment_score', 'relevance_score', 'ticker_sentiment_score','affected_topic_relevance_score']\n",
    "for col in numeric_columns:\n",
    "    if col in filtered_df.columns:\n",
    "        filtered_df[col] = pd.to_numeric(filtered_df[col], errors='coerce')\n",
    "\n",
    "        # Agrupar por hora y calcular agregados\n",
    "        filtered_df = filtered_df.groupby('datetime').agg({\n",
    "            'overall_sentiment_score': lambda x: round(x.mean(), 4),  # Promedio con 4 decimales\n",
    "            'relevance_score': lambda x: round(x.mean(), 4),  # Promedio con 4 decimales\n",
    "            'ticker_sentiment_score': lambda x: round(x.mean(), 4),  # Promedio con 4 decimales\n",
    "            'affected_topic_relevance_score': lambda x: round(x.mean(), 4),  # Promedio con 4 decimales\n",
    "            'title': 'nunique'  # Número de títulos únicos para contar noticias distintas\n",
    "        }).reset_index()\n",
    "\n",
    "        # Renombrar la columna del conteo para mayor claridad\n",
    "        filtered_df = filtered_df.rename(columns={'overall_sentiment_score': 'ticker_overall_sentiment_score_mean'})\n",
    "        filtered_df = filtered_df.rename(columns={'relevance_score': 'ticker_relevance_score_mean'})\n",
    "        filtered_df = filtered_df.rename(columns={'ticker_sentiment_score': 'ticker_sentiment_score_mean'})\n",
    "        filtered_df = filtered_df.rename(columns={'affected_topic_relevance_score': 'ticker_affected_topic_relevance_score_mean'})\n",
    "        filtered_df = filtered_df.rename(columns={'title': 'distinct_news_count'})\n",
    "        filtered_df = filtered_df.sort_values(by='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 datetime  Technology_overall_sentiment_score_mean  \\\n",
      "0     2022-03-05 01:00:00                                  -0.2232   \n",
      "1     2022-03-05 05:00:00                                  -0.0325   \n",
      "2     2022-03-07 09:00:00                                  -0.1322   \n",
      "3     2022-03-07 11:00:00                                   0.2263   \n",
      "4     2022-03-07 14:00:00                                  -0.1873   \n",
      "...                   ...                                      ...   \n",
      "6600  2025-02-01 04:00:00                                   0.2831   \n",
      "6601  2025-02-01 06:00:00                                   0.2338   \n",
      "6602  2025-02-01 08:00:00                                   0.2225   \n",
      "6603  2025-02-01 09:00:00                                   0.2324   \n",
      "6604  2025-02-01 10:00:00                                  -0.0220   \n",
      "\n",
      "      Technology_affected_topic_relevance_score_mean  \\\n",
      "0                                             0.2000   \n",
      "1                                             1.0000   \n",
      "2                                             0.5000   \n",
      "3                                             1.0000   \n",
      "4                                             1.0000   \n",
      "...                                              ...   \n",
      "6600                                          0.2917   \n",
      "6601                                          0.5000   \n",
      "6602                                          0.3333   \n",
      "6603                                          0.6667   \n",
      "6604                                          0.8333   \n",
      "\n",
      "      Technology_distinct_news_count  \n",
      "0                                1.0  \n",
      "1                                1.0  \n",
      "2                                1.0  \n",
      "3                                1.0  \n",
      "4                                4.0  \n",
      "...                              ...  \n",
      "6600                             2.0  \n",
      "6601                             1.0  \n",
      "6602                             1.0  \n",
      "6603                             2.0  \n",
      "6604                             3.0  \n",
      "\n",
      "[6605 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "topic = 'Technology'\n",
    "\n",
    "# Identificar títulos asociados al target_ticker\n",
    "titles_with_target_ticker = original_df[original_df['ticker'] == target_ticker]['title'].unique()\n",
    "\n",
    "# Excluir todas las noticias cuyos títulos estén relacionados con el target_ticker\n",
    "non_related_news = original_df[~original_df['title'].isin(titles_with_target_ticker)].copy()\n",
    "\n",
    "# Excluir filas que no tienen un tópico válido en el campo affected_topic\n",
    "non_related_news = non_related_news[non_related_news['affected_topic'].notnull()]\n",
    "\n",
    "# Filtrar por tópico\n",
    "topic_data = non_related_news[non_related_news['affected_topic'] == topic]\n",
    "\n",
    "# Seleccionar columnas relevantes y eliminar duplicados por datetime\n",
    "topic_data = topic_data[['datetime', 'title', 'overall_sentiment_score', 'affected_topic_relevance_score']].drop_duplicates()\n",
    "\n",
    "# Contar el número de noticias por datetime\n",
    "topic_data['news_count'] = topic_data.groupby('datetime')['datetime'].transform('count')\n",
    "\n",
    "# Agrupar por datetime y calcular métricas similares a las del ticker\n",
    "topic_metrics = topic_data.groupby('datetime').agg({\n",
    "    'overall_sentiment_score': lambda x: round(x.mean(), 4),\n",
    "    'affected_topic_relevance_score': lambda x: round(x.mean(), 4),\n",
    "    'news_count': lambda x: x.mean()\n",
    "    }).rename(columns={\n",
    "        'overall_sentiment_score': f'{topic}_overall_sentiment_score_mean',\n",
    "        'affected_topic_relevance_score': f'{topic}_affected_topic_relevance_score_mean',\n",
    "        'news_count': f'{topic}_distinct_news_count'\n",
    "    }).reset_index()\n",
    "\n",
    "print(topic_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 datetime  Technology_overall_sentiment_score_mean  \\\n",
      "0     2022-03-05 01:00:00                                  -0.2232   \n",
      "1     2022-03-05 05:00:00                                  -0.0325   \n",
      "2     2022-03-07 09:00:00                                  -0.1322   \n",
      "3     2022-03-07 11:00:00                                   0.2263   \n",
      "4     2022-03-07 14:00:00                                  -0.1873   \n",
      "...                   ...                                      ...   \n",
      "7214  2025-02-01 04:00:00                                   0.2831   \n",
      "7215  2025-02-01 06:00:00                                   0.2338   \n",
      "7216  2025-02-01 08:00:00                                   0.2225   \n",
      "7217  2025-02-01 09:00:00                                   0.2324   \n",
      "7218  2025-02-01 10:00:00                                  -0.0220   \n",
      "\n",
      "      Technology_affected_topic_relevance_score_mean  \\\n",
      "0                                             0.2000   \n",
      "1                                             1.0000   \n",
      "2                                             0.5000   \n",
      "3                                             1.0000   \n",
      "4                                             1.0000   \n",
      "...                                              ...   \n",
      "7214                                          0.2917   \n",
      "7215                                          0.5000   \n",
      "7216                                          0.3333   \n",
      "7217                                          0.6667   \n",
      "7218                                          0.8333   \n",
      "\n",
      "      Technology_distinct_news_count  ticker_overall_sentiment_score_mean  \\\n",
      "0                                1.0                                  NaN   \n",
      "1                                1.0                                  NaN   \n",
      "2                                1.0                                  NaN   \n",
      "3                                1.0                                  NaN   \n",
      "4                                4.0                                  NaN   \n",
      "...                              ...                                  ...   \n",
      "7214                             2.0                                  NaN   \n",
      "7215                             1.0                                  NaN   \n",
      "7216                             1.0                               0.3949   \n",
      "7217                             2.0                               0.1759   \n",
      "7218                             3.0                               0.2281   \n",
      "\n",
      "      ticker_relevance_score_mean  ticker_sentiment_score_mean  \\\n",
      "0                             NaN                          NaN   \n",
      "1                             NaN                          NaN   \n",
      "2                             NaN                          NaN   \n",
      "3                             NaN                          NaN   \n",
      "4                             NaN                          NaN   \n",
      "...                           ...                          ...   \n",
      "7214                          NaN                          NaN   \n",
      "7215                          NaN                          NaN   \n",
      "7216                       0.1150                      -0.0045   \n",
      "7217                       0.2500                       0.0947   \n",
      "7218                       0.3179                       0.2075   \n",
      "\n",
      "      ticker_affected_topic_relevance_score_mean  distinct_news_count  \n",
      "0                                            NaN                  NaN  \n",
      "1                                            NaN                  NaN  \n",
      "2                                            NaN                  NaN  \n",
      "3                                            NaN                  NaN  \n",
      "4                                            NaN                  NaN  \n",
      "...                                          ...                  ...  \n",
      "7214                                         NaN                  NaN  \n",
      "7215                                         NaN                  NaN  \n",
      "7216                                      0.5502                  1.0  \n",
      "7217                                      0.5037                  3.0  \n",
      "7218                                      0.5585                  1.0  \n",
      "\n",
      "[7219 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(topic_metrics, filtered_df, on='datetime', how='outer')\n",
    "\n",
    "print(merged_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_DS_3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
